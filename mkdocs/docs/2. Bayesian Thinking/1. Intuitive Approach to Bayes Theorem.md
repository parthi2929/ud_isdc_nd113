## Part 1

This article tries to lay a foundational understanding for Bayes theorem. Especially what does it actually mean when you multiply two probabilities. This stems from Bayes theorem and we will explore it with an example.  

<br>

<strong>Note</strong>: We will use the wonderful example provided in Quora, <a href="https://www.quora.com/What-is-an-intuitive-explanation-of-Bayes-Rule">here</a> and try to elaborate visually.  

<br>

<strong>Problem</strong>: Given the weather forecast(WF) is rain, what is probability that it would actually rain in <strong>my area</strong>?  

<br>
 
<strong>Assumptions</strong>: Out of 100 days rained, WF predicted correctly 90% of the time that it rained. Out of 100 days dry, WF predicted correctly 80% of the time, that it would be dry. In my area, out of 100 days, 10 days it would rain and 90 days would be dry.  

<br>

We could visualize them as below. <em>Visualization is the key here in this article to understand, why the heck we "<strong>multiply</strong>" probabilities.</em>

<figure>
<img class="alignnone size-full wp-image-86" src="../../images/2018-03-17_19h14_15.png" alt="2018-03-17_19h14_15" width="971" height="242" />
<figcaption align='center'>Figure 1</figcaption>
</figure>

If we try to apply WF for both rain and dry cases in my area, it would be something like this (not drawn to scale).  


<div style="display: flex; justify-content: center;">
<figure>
<img src="../../images/2018-03-17_19h14_271.png" alt="2018-03-17_19h14_27" width="442" height="237"/>
<figcaption align='center'>Figure 2</figcaption>
</figure>
</div>

For 10% of time raining in my area, WF would be 90% accurate to predict that it would rain. In other words, <strong>out of 10%</strong> days raining, WF would be <strong>90% of the time</strong>, correctly would predict as rain.  

<br>

<span style="color: #0000ff;">90% out of 10% days raining is 90%(10%) = (0.9)(0.1) = 0.09 or 9%</span>   

<br>

<span style="color: #0000ff;">Thus, 9% of the time in my area, its rains <strong>and</strong> WF would predict correctly as rain. </span>   

<br>

That's it. This is how the multiplication is evolving out of our logic. Its not yet over.   

<br>


From Figure 2, again, for 90% of time being dry in my area, WF would be wrong 20% of the time. That is WF would be predicting as rain, but it would be dry here. In other words, <strong>out of 90%</strong> days being dry, WF would be <strong>20% of the time</strong> wrongly predicting as rain.  

<br>


<span style="color: #0000ff;">20% out of 90% days being dry is = (0.2)(0.9) = 0.18 or 18%</span>   

<br>


<span style="color: #0000ff;">Thus, 18% of the time in my area, its dry, <strong>and</strong> WF would wrongly predict as rain.</span>   

<br>


In terms of probability, if   

<br>

$$
p(R_{\text{Act}})=\text{Probability of raining in my area}
\\
p(D_{\text{Act}})=\text{Probability of dryness in my area}
\\
p(R_{\text{WF}})=\text{Probability of WF as rain generally}
\\
p(D_{\text{WF}})=\text{Probability of WF as dry generally}\\p(R_{\text{Act}} \cap R_{\text{WF}}) = \text{Probability that it rains and WF also predicts rain} \\
p(D_{\text{Act}} \cap R_{\text{WF}}) = \text{Probability that it is dry and WF predicts rain}
$$

Then what we inferred in words above, can be expressed as,  

<br>

$$
p(R_{\text{Act}} \cap R_{\text{WF}}) = (0.1)(0.9) = 0.09 \\
p(D_{\text{Act}} \cap R_{\text{WF}}) = (0.9)(0.2) = 0.18  \tag{1}  
$$  

Putting it another way, out of 100 days in my area, {9 days it rains and WF also predicts as rain} and {18 days its dry and WF predicts as rain}.  

<br>


Let us stop a moment and recall basic probability now:  

<br>


$ \text {Probability of favourable outcome} = \frac{\text {No of favourable outcomes}}{\text {Total no of possible outcomes}} $  

<br>


In our case,  

<br>


$$
\text {Total no of days its rain given WF says rain} = 9  
\\
\text {Total no of days its dry given WF says rain} = 18
\\
\text {Total no of days either rain or dry given WF says rain} = 9 + 18 = 27
$$  

<br>


Deploying that,   

<br>

$$  
p(\text {actual rain given WF says rain}) = \frac{9}{9+18} = \frac{1}{3} = 0.33\\
p(\text {actually dry given WF says rain}) = \frac{18}{9+18} = \frac{2}{3} = 0.66
$$  

<br>

We have a math notation for LHS..  

<br>

$$
p(R_{\text{Act}} \mid R_{\text{WF}}) = 0.33\\
p(D_{\text{Act}} \mid R_{\text{WF}}) = 0.66  \tag{2}
$$  

<br>

Combining equations (1) and (2), we could thus see,  

<br>

$$ 
p(R_{\text{Act}} \mid R_{\text{WF}}) =
\frac{p(R_{\text{Act}} \cap R_{\text{WF}})}{p(R_{\text{Act}} \cap R_{\text{WF}}) + p(D_{\text{Act}} \cap R_{\text{WF}})}  \\\\
p(D_{\text{Act}} \mid R_{\text{WF}}) =
\frac{p(D_{\text{Act}} \cap R_{\text{WF}})}{p(R_{\text{Act}} \cap R_{\text{WF}}) + p(D_{\text{Act}} \cap R_{\text{WF}})}
$$</p>  

<br>

This in essence is Bayes' theorem. Note, we inferred visually, arrived at values and then combining observations, arrived at the formula. We did not apply formula and arrive at solution. Hope, thus this provides a good intuition to start with in Bayes' theorem.  

<br>


## Part 2 

<br>

Let us now try to tackle few questions in the course. 

<br>

<a href="https://youtu.be/EL5z2lUuxY4" target="_blank" rel="noopener nofollow">Bayes theorem link in Udacity</a> : How is it 8.3%?  

<br>

<a href="https://www.khanacademy.org/math/ap-statistics/probability-ap/stats-conditional-probability/v/bayes-theorem-visualized" target="_blank" rel="noopener nofollow">Conditional probability with Bayes' Theorem: </a>Why the tree should be balanced in 2nd example of 2 fair coins and 1 biased coin?  

<br>

<a href="https://math.stackexchange.com/questions/2680957/what-is-pbiased-coin-given-heads-in-2-fair-coin-1-biased-coin-experiment" target="_blank" rel="noopener nofollow">My blocking point/doubt in detail.</a>  

<br>

<strong>Example 1 (Khan academy): </strong>There are 2 fair coins (fair coin = 1 head and 1 tail), and 1 biased coin (which is when flipped gives heads 2/3rd of the time, and tail 1/3rd of the time) in a bag. Now one picks up a coin from the bag, and flips it. Given that it is heads, what is the probability that the coin is biased?  

<br>

Let us assume,  

<br>

<strong>p(B)</strong> = probability of biased coin<br>
<strong>p(B/H)</strong> = probability of biased coin, given its Heads.<br>
<strong>p(H)</strong> = probability of coin being Heads<br>
<strong>p(H/B)</strong> = probability of coin being Heads, given its biased<br>
<strong>p(B and H)</strong> = probability of coin being both biased and heads.<br>


Let us try to visualize with a tree diagram (unfolding of events, with possible outcomes and their probabilities).  

<br>

During 1st event, when a coin is picked up from the bag, it could be either Fair or Biased. Since there are 2 Fair coins and 1 Biased coin, we could visualize it as follows with probabilities assigned to each.  

<br>

<div style="display: flex; justify-content: center;">
<figure>
<img src="../../images/2018-03-08_15h31_11.png"/>
<figcaption align='center'>Figure 1</figcaption>
</figure>
</div>

<br>


<p style="text-align: left;" align="”center”">
p(B) = probability of coin being biased
p(F) = probability of fair coin</p>
<p align="”center”">Since 2 fair coins,</p>  

<br>


$$
p(F)={\frac {\text {Number of fair coins}} {\text {Total number of coins}}} = \frac{2}{3}\\\\
p(B)={\frac {\text {Number of biased coins}} {\text {Total number of coins}}} = \frac{1}{3}
$$  

<br>


<p align="”center”">Note that,obviously, as output is either biased or fair coin</p>

$$
p(F) + p(B) = \frac{2}{3} + \frac{1}{3} = 1
$$  

<br>


<p align="”center”">This total probability being 1 should be satisfied from all branches of any node in the tree.</p><br>
<p align="”center”">This is not yet over. A coin is picked up from 3 sets. Thus we derive one more level as follows.</p><br>

<br>

<div style="display: flex; justify-content: center;">
<figure>
<img src="../../images/2018-03-08_19h29_10.png"/>
<figcaption align='center'>Figure 2</figcaption>
</figure>
</div>

<br>

Once a coin is picked up out of "FFB" set, if picked up coin is "F", then remaining set for further possibility has only "FB". And outcome out of this remaining set could be either "F" or "B", each having equal chance, thus halved probability.  

<br>

Similarly, once "B" is picked up, with remaining set containing "FF", the outcome is always only a "F" with 100% certainty. This is also depicted above as probability being 1.  

<br>

Note, now we have multiple probabilities for p(F) and p(B). This is now mainly because we did not just have 2 coins to start with "FB", but "FFB", thus this additional level needed.  

<br>

In same way, now we extend to the H and T possibilities of each end node. Note the p(H) and p(T) for B in particular where, heads has 2/3rd times chance of showing up.  

<br>

<div style="display: flex; justify-content: center;">
<figure>
<img src="../../images/2018-03-08_19h36_08.png"/>
<figcaption align='center'>Figure 3</figcaption>
</figure>
</div>

<br>

That is it. We have drawn a tree of all possible outcomes, with associated probabilities.  

<br>

Note that, <strong>p (B and H) = p (H and B)</strong>, both are same. That is,  

<br>

p( final outcome being both biased coin with heads) = p(final outcome of heads being a biased coin).  

<br>

Note that p( A and B) is not p (A | B). Both mean different, with latter being conditional probability.  

<br>

From Figure 3, p (B and H) is the highlighted path, thus we multiply their probabilities in the path.  

<br>

<div style="display: flex; justify-content: center;">
<figure>
<img src="../../images/2018-03-08_19h45_28.png"/>
<figcaption align='center'>Figure 4</figcaption>
</figure>
</div>

<br>

$p(\text {B and H})= \frac{2}{3}. \frac{1}{2}.\frac{2}{3} = \frac{4}{18} = \frac{2}{9}$  

<br>

Recall the question, <em>"Given that picked up coin is heads, what is the probability that the coin is biased?"</em>  

<br>

That is, <strong>given</strong> H, what is p(B). In other words, what is <strong>p(B|H)</strong>?  

<br>

Notice, here the prior event is "heads" being picked up. Let us calculate all the probabilities of heads being picked up. That is <strong>p(H)</strong>.  

<br>

<div style="display: flex; justify-content: center;">
<figure>
<img src="../../images/2018-03-08_20h03_04.png"/>
<figcaption align='center'>Figure 5</figcaption>
</figure>
</div>

<br>

$p(\text {H})= \frac{2}{3}. \frac{1}{2}.\frac{1}{2} + \frac{2}{3}.\frac{1}{2}.\frac{2}{3} + \frac{1}{3}.1.\frac{1}{2} = \frac{2}{12} + \frac{4}{18} + \frac{1}{6} = \frac{15}{27}= \frac{5}{9}$  

<br>

Coming back to <strong>p(B and H)</strong>, it can be interpreted as  

<br>

p( final outcome being <span style="color: #0000ff;">both biased coin and heads</span>) = p (outcome of <span style="color: #0000ff;">all possible heads scenario</span>) x p (outcome of getting <span style="color: #0000ff;">biased coin, given heads</span> has occurred).  

<br>

$p(\text {B and H})= p(\text {H}) . p(\text {B} \mid \text {H})$  

<br>

Re read. This is the very crux of our solution. The latter in above equation can now be readily derived.  

<br>

$p(\text {B} \mid \text {H}) = \frac{p(\text {B and H})}{p(\text {H})} = \frac{2}{9} . \frac{9}{5}= \frac{2}{5}$  

<br>

Thus, the probability of getting biased coin, given heads occurred is $\frac{ 2 }{ 5 }$. This conforms with Khan academy's answer as well (which is $\frac{ 4 }{ 10 }$). Note that even though I have not yet understood, why the tree (which is different) in Khan academy's video has to be balanced, I am now able to derive the same solution via a slightly different approach.  

<br>

<strong>Example 2 (Udacity): </strong>Suppose there is a known statistics that 1% of population gets cancer. When we then test them, there is 90% chance, test is positive, if that person being tested has cancer. Similarly, there is also 90% chance, test is negative, if that person being tested does not have cancer. As first event, we test a person, and the result is positive. Now what is the probability that the person has cancer?  

<br>

Let us assume,  

<br>

p(C) = probability of cancer<br>
p(+/C) = probability of test being +, <strong>given</strong> the person has cancer.<br>
p(+) = probability of test being +<br>
p(C/+) = probability of person having cancer, <strong>given</strong> the test is positive <br>
p(C and +) = probability of person having cancer and test being positive.<br>

Visualizing in tree diagram, just like previous problem..  

<br>


<div style="display: flex; justify-content: center;">
<figure>
<img src="../../images/2018-03-08_21h27_41.png"/>
<figcaption align='center'>Figure 1</figcaption>
</figure>
</div>

<br>

Rephrasing the question, what is the probability of person having cancer, <strong>given</strong> the test conducted on him is positive. In other words, what is <strong>p(C/+)</strong>.  

<br>

From the tree, we can derive the probability of person having cancer and test being positive, that is <strong>p(C and +)</strong>  

<br>

<div style="display: flex; justify-content: center;">
<figure>
<img src="../../images/2018-03-08_21h31_24.png"/>
<figcaption align='center'>Figure 2</figcaption>
</figure>
</div>

<br>

<p style="text-align: center;"><strong>p(C and +)</strong> = (0.01) (0.9) = 0.009</p><br>
From the tree, we can also derive probability of all outcomes of test being positive, that is <strong>p(+)</strong><br>

<br>


<div style="display: flex; justify-content: center;">
<figure>
<img src="../../images/2018-03-08_21h34_52.png"/>
<figcaption align='center'>Figure 3</figcaption>
</figure>
</div>

<br>

<p style="text-align: center;"><strong>p(+)</strong> = (0.01)(0.9) + (0.99)(0.1) = 0.108</p>  
<br>

We now know from previous example,  

<br>

p(C and +) = p(+) . p(C/+)  

<br>

Thus,  

<br>

$p(\text {C/+}) = \frac{p(\text{C and +})}{p(\text{+})}= \frac{0.009}{0.108} = 0.0833$  

<br>

Thus, the probability of a person having cancer, given the test is positive, is 0.0833 or $8.3$ which also conforms with the answer in Udacity.  

<br>

Summarizing, with single approach we are able to solve both cases, as intuitive as possible (hopefully), even when the methods handled in both cases by respective platforms are not fully clear.  

<br>

<strong>Note</strong>: I have not yet gotten in to generalized formula and leaving that to readers'. Specifically in above examples, the denominator probability, that is <strong>p(H)</strong> in former case, or <strong>p(+)</strong> in latter case, is actually summation of those probabilities, so in strict sense, should be prefixed with a summation symbol, and index. For brevity, I stuck to the simple form. Once you start sorting out more examples with this approach, the summation and thus the intuition behind the general formula would become clearer.  

<br>

General Bayes' formula with summation (inference now left to reader as food for thought):  

<br>


$$
p(A_i \mid B) = \frac{p(B \mid A_i)p(A_i)}{\sum_{i=1}^n p(B \mid A_i)p(A_i)}
$$

<br>

