# 4. Robot Localization

## Part 1 (Sense)  

This article explains one of the 2 main concepts discussed in Udacity's Self Driving Car -&gt; Bayesian Thinking -&gt; Lesson 11:  Robot Localization.  

<br>


<strong>Situation</strong>: We have a 1 D world space with 5 different grid cells. They are colored red or green as shown below. Robot could be anywhere across this space, and all cells have equally likely chance. Thus we assume uniform probability distribution (1/5) = 0.2 for each cell. Also remember, the 1 D is cyclic, so if robot is in Cell 5, its next step is Cell 1. This is to keep our exercise simple.  

<br>

<div style="display: flex; justify-content: center;">
<figure>
<img src="../../images/2018-03-21_19h04_20.png"/>
<figcaption align='center'>Figure 1</figcaption>
</figure>
</div>  

<br>

If X<sub>i</sub> represents the cell location, then,  

<p>$$
\begin{align}
p({{X}_{1}})=0.2\\
p({{X}_{2}})=0.2\\
p({{X}_{3}})=0.2\\
p({{X}_{4}})=0.2\\
p({{X}_{5}})=0.2
\end{align}
$$</p>  

<br> 


We also assume that, robot's sensor has accuracy as below.  

<br>

<div style="display: flex; justify-content: center;">
<figure>
<img src="../../images/2018-03-21_19h05_29.png"/>
<figcaption align='center'>Figure 2</figcaption>
</figure>
</div>

<br>

<strong>Problem</strong>: Robot senses that the cell it is standing on, is "<strong>Red</strong>". What is the probability of robot location in each cell X<sub>i</sub>?  

<br>

Intuitively, then the probability of red cells should increase (as Robot mostly should be there), and green cells should decrease (as robot is not ideal and possibility of errors). Let us check mathematically. Using our earlier technique <a href="https://parthibanrajendran.wordpress.com/2018/03/17/0-bayes-theorem-intuitive-foundation/" target="_blank" rel="noopener">here</a>, we could apply the evidence on prior situation as below.  

<br> 

<div style="display: flex; justify-content: center;">
<figure>
<img src="../../images/2018-03-21_19h26_03.png"/>
<figcaption align='center'>Figure 3</figcaption>
</figure>
</div>

<br>

For 1st cell which is green, there is 20% chance that sensor read it as "red". Thus probability of location being green <strong>and</strong> sensor reading as "red" would be <strong>20% out of 20%</strong> chance the green cell has. In other words, (0.2)(0.2) = 0.04. Similarly, we could calculate for all cells, and put in mathematical notation as below.  

<br>

<p>$\displaystyle \begin{array}{l}p({{X}_{1}}\cap Red)=\left( {0.2} \right)\left( {0.2} \right)=0.04\\p({{X}_{2}}\cap Red)=\left( {0.2} \right)(0.6)=0.12\\p({{X}_{3}}\cap Red)=\left( {0.2} \right)(0.6)=0.12\\p({{X}_{4}}\cap Red)=\left( {0.2} \right)\left( {0.2} \right)=0.04\\p({{X}_{5}}\cap Red)=\left( {0.2} \right)\left( {0.2} \right)=0.04\end{array}$</p>  

<br>

Summing up,  

<br>  

<p>$$
\displaystyle \sum\limits_{{i=1}}^{n}{{p({{X}_{i}}\cap Red)}}=0.04+0.12+0.12+0.04+0.04=0.36  \tag{1}
$$</p>  

<br>

We have thus calculated joint probability. Coming to posterior which is also the problem to be solved: Given the sensor reading is "red", what is the probability for each cell? We could readily use Bayes' theorem  

<br>

<p>$$
\displaystyle \begin{array}{l}p\left( {{{X}_{i}}|\text{Red}} \right)\text{ }=\frac{{p({{X}_{i}}\cap \text{Red})}}{{p(\text{Red})}}\\\\\text{ }=\frac{{p({{X}_{i}}\cap \text{Red})}}{{\sum\limits_{{k=1}}^{n}{{p({{X}_{k}}\cap \text{Red}}})}}\end{array} \tag{2}
$$</p>

<br> 

Applying for each cell,  

<br>  

<p>$ \displaystyle 
\begin{array}{l}
p({{X}_{1}}|~\text{Red})=\left( {\frac{{0.04}}{{.36}}} \right)=0.111\\
p({{X}_{2}}|~\text{Red})=\left( {\frac{{0.12}}{{.36}}} \right)=0.333\\
p({{X}_{3}}|~\text{Red})=\left( {\frac{{0.12}}{{.36}}} \right)=0.333\\
p({{X}_{4}}|~\text{Red})=\left( {\frac{{0.04}}{{.36}}} \right)=0.111\\
p({{X}_{5}}|~\text{Red})=\left( {\frac{{0.04}}{{.36}}} \right)=0.111
\end{array}$</p>  

<br>

Note that, posterior probability adds up to 1 again like prior.  

<br>  

<p>$ \displaystyle \sum\limits_{{i=1}}^{n}{{p\left( {{{X}_{i}}|\text{Red}} \right)}}=1$</p>

Also, again using Baye's theorem for RHS for (2), we could re write it as below.  

<p>
$$
\displaystyle \begin{array}{l}p\left( {{{X}_{i}}|\text{Red}} \right)=\frac{{p({{X}_{i}}\cap \text{Red})}}{{\sum\limits_{{k=1}}^{n}{{p({{X}_{k}}\cap \text{Red)}}}}}\\\\\text{ }=\frac{{p(\text{Red }\!\!|\!\!\text{ }{{X}_{i}})p({{X}_{i}})}}{{\sum\limits_{{k=1}}^{n}{{p(\text{Red }\!\!|\!\!\text{ }{{X}_{k}})p({{X}_{k}})}}}}\end{array}
$$
</p>  

<br>

Thus finally our posterior probability distribution in our visual summary:  

<br>

<div style="display: flex; justify-content: center;">
<figure>
<img src="../../images/2018-03-21_20h31_19.png"/>
<figcaption align='center'>Figure 4</figcaption>
</figure>
</div>

<br>

Note, that as intuitively imagined earlier, the probability for red cells have increased from 0.2 to 0.33 while the green cells has their probability decreased from 0.2 to 0.111. Now robot is more certain of its location :)  

<br>

So remember, each time, robot senses' its certainty increases. Its more sure of its location.  

<br>

<strong>Food for thought:</strong> What happens to the probability distribution if we ask robot to keep sensing for many times. Intuitively, then the red cells each should achieve 0.5 probability eventually and rest going to 0. Let us check this out pro grammatically after implementing sense function.  

<br>

<strong>Python Implementation:</strong>

Suppose,  

<br>

<span style="color:#0000ff;"><em>p</em></span> = list of prior probabilities of all cells
<span style="color:#0000ff;"><em>world</em></span> = list of color of each cell in same order (kinda map given to robot)
<span style="color:#0000ff;"><em>Z</em></span> = robot's measurement (in our test case, 'red')
<span style="color:#0000ff;"><em>pHit</em></span> = probability of robot correctly sensing red when its actually red
<span style="color:#0000ff;"><em>pMiss</em></span> = probability of robot wrongly sensing red, when its actually green  

<br>

then,

<ol>
    <li>for each element in p, we could simply calculate the joint probability first by multiplying with pHit, if cell is red, or pMiss if cell is green</li>
    <li>calculate the p(Red) by summing up the joint probabilities</li>
    <li>calculate prior probability by diving each element again with the sum</li>
</ol>

Thus the implementation is as follows <em>(slightly different than Udacity's as we derived directly from logic without referring it)</em>.

```python
p=[0.2, 0.2, 0.2, 0.2, 0.2]
world=['green', 'red', 'red', 'green', 'green']
pHit = 0.6
pMiss = 0.2
def sense(p, Z):
    """
    p = initial probability distribution list
    Z = each measurement
    q = new normalized distribution list
    """
    q = []
    for each_index in range(len(p)):
        if (world[each_index] == Z):
            q.append(p[each_index]<em>pHit)
        else:
            q.append(p[each_index]</em>pMiss)
    total = sum(q)
    q = [ x/total for x in q]
    return q

print("Prior probability: " + str(p))
print("Posterior probability: " + str(sense(p,'red')))
```

Output:


<div style="display: flex; justify-content: center;">
<figure>
<img src="../../images/2018-03-21_20h48_08.png"/>
<figcaption align='center'>Figure 5</figcaption>
</figure>
</div>


Coming back to food for thought, we could simulate asking robot to sense so many times by calling sense repeatedly with measurement as 'red'. Result is as expected.

```python
p=[0.2, 0.2, 0.2, 0.2, 0.2]
print("Prior probability: " + str(p))
for i in range(1000):
    p = sense(p, 'red')
print("Posterior probability: " + str(sense(p,'red')))
```

Output:

<div style="display: flex; justify-content: center;">
<figure>
<img src="../../images/2018-03-22_15h05_27.png"/>
<figcaption align='center'>Figure 6</figcaption>
</figure>
</div>

So when you keep sensing new information, your certainty increases.

## Part 2 (Move)

We will now see, what happens to probability distributions when robot moves.  

<br>

<strong>Situation</strong>: We have a 1 D world space with 5 grid cells. Robot could be anywhere across this space and we assume a probability distribution like below (say, due to a previous sense function, few cells have more probability). That is, we assume robot has equally likely chance of being either at X<sub>2</sub> or X<sub>4</sub>, and not anywhere else. Also world is cyclic that is after X<sub>5</sub> , next cell is X<sub>1</sub>.  

<br>

<div style="display: flex; justify-content: center;">
<figure>
<img src="../../images/2018-03-22_08h57_07.png"/>
<figcaption align='center'>Figure 1</figcaption>
</figure>
</div>

<br>

If X<sub>i</sub> represents the cell location, then  

<br>

<p>
$$
 \displaystyle \begin{array}{l}p({{X}_{1}})=0\\p({{X}_{2}})=0.5\\p({{X}_{3}})=0\\p({{X}_{4}})=0.5\\p({{X}_{5}})=0\end{array} \tag{1}
$$
</p>  

Let us also assume robot moves in 2 steps, always to its right side, and it's motion accuracy as below.  



<div style="display: flex; justify-content: center;">
<figure>
<img src="../../images/2018-03-22_08h58_25.png"/>
<figcaption align='center'>Figure 2</figcaption>
</figure>
</div>

<strong>Problem</strong>: Robot moves 2 steps right. What is the probability of robot location in each cell X<sub>i</sub> ? Appears like posterior, but we will get to that soon.  

<br>

Intuitively, since the robot as per our assumption could have moved only from X<span style="font-size:13.3333px;">2</span> or X<span style="font-size:13.3333px;">4</span> , their probability should decrease, and probable target cells' probability increase. Generically, any cell's probability, depends on robot arriving at it from adjacent cells' either by undershoot or exact or overshoot from cells' left side (caz robot always move in right direction). For eg, For X<sub>1</sub> ,the only way robot would have arrived is if robot was earlier in X<sub>4</sub> and did exact 2 steps motion to its right.  

<br>

Since both probability (prior and posterior) is on same sample space "location" we shall differentiate the event by time notation for easier understanding. Further, there is also mix up of probabilities (one cell might receive robot from more than one source. For eg, X<sub>5</sub> might have received either by robot undershooting from X<sub>4</sub> or overshooting from X<sub>2</sub> .  

<br>

We will thus divide the cases by all possible current locations, calculate the probabilities individually and then add up. Don't worry, it is for this purpose, we assumed only 2 locations having prior probability of having the robot. We have thus only 2 cases as below.  

<br>

<strong>Case A</strong>: Robot moving from X<sub>2</sub> .  Including time notation, we could visualize its further movement with probabilities as below.  

<br>

For example, out of 50% of being at X<sub>2</sub>, robot has 10% chance of ending up at X<sub>3</sub> after its movement, as it might undershoot. Other locations could be understood in similar manner.

<br>

<div style="display: flex; justify-content: center;">
<figure>
<img src="../../images/2018-03-22_10h24_25.png"/>
<figcaption align='center'>Figure 3: Case A</figcaption>
</figure>
</div>  

<br>  

<strong>Case B</strong>: Robot moving from X<sub>4</sub>. Its visualization could be as follows.

<br>

<div style="display: flex; justify-content: center;">
<figure>
<img src="../../images/2018-03-22_10h31_34.png"/>
<figcaption align='center'>Figure 4: Case B</figcaption>
</figure>
</div>  

<br>

Now, for each cell's probability, we could calculate simply $ \displaystyle p(A\cup B)$ as below.  

<br>

<p>
$$ 
\displaystyle p(A\cup B)=p(A)+p(B)-p(A\cap B)=p(A)+p(B) \tag{2}
$$
</p>  

<br> 


$ \displaystyle p(A\cap B)=0$  because, robot could have moved either from X<sub>2</sub> or X<sub>4</sub> not both. (We are not including quantum effects here ;).  

<br>

Now we can derive individual cell's probabilities in both cases as below. For eg, in case A, $ \displaystyle p(X_{1}^{t})=0$ because, there is no way, robot could have arrived at X<sub>1</sub> from X<sub>2</sub> .  Similarly for others. Make sure you fully able to  comprehend below equations , as we would generalize this shortly.  

<br>


$ \displaystyle p(A)$:  

<p>
$$ \displaystyle \begin{array}{l}p(X_{1}^{t})=0\\p(X_{2}^{t})=0\\p(X_{3}^{t})=p(X_{2}^{{t-1}})p(X_{3}^{t}|X_{2}^{{t-1}})=p(X_{2}^{{t-1}})(0.1)=(0.5)(0.1)=0.05\\p(X_{4}^{t})=p(X_{2}^{{t-1}})p(X_{4}^{t}|X_{2}^{{t-1}})=p(X_{2}^{{t-1}})(0.8)=(0.5)(0.8)=0.40\\p(X_{5}^{t})=p(X_{2}^{{t-1}})p(X_{5}^{t}|X_{2}^{{t-1}})=p(X_{2}^{{t-1}})(0.1)=(0.5)(0.1)=0.05\end{array} \tag{3}
$$
</p>  

<br>  

$ \displaystyle p(B)$:

<p>
$$ \displaystyle \begin{array}{l}p(X_{1}^{t})=p(X_{4}^{{t-1}})p(X_{1}^{t}|X_{4}^{{t-1}})=p(X_{4}^{{t-1}})(0.8)=(0.5)(0.8)=0.40\\p(X_{2}^{t})=p(X_{4}^{{t-1}})p(X_{2}^{t}|X_{4}^{{t-1}})=p(X_{4}^{{t-1}})(0.1)=(0.5)(0.1)=0.05\\p(X_{3}^{t})=0\\p(X_{4}^{t})=0\\p(X_{5}^{t})=p(X_{4}^{{t-1}})p(X_{5}^{t}|X_{4}^{{t-1}})=p(X_{4}^{{t-1}})(0.1)=(0.5)(0.1)=0.05\end{array} \tag{4} $$</p>  

<br>

Combining (3)and (4) using (2), we thus could arrive at final probabilities of each cell.  

<br>

<p>
$$ \displaystyle \begin{array}{l}p(X_{1}^{t})=p(X_{4}^{{t-1}})p(X_{1}^{t}|X_{4}^{{t-1}})=p(X_{4}^{{t-1}})(0.8)=(0.5)(0.8)=0.40\\p(X_{2}^{t})=p(X_{4}^{{t-1}})p(X_{2}^{t}|X_{4}^{{t-1}})=p(X_{4}^{{t-1}})(0.1)=(0.5)(0.1)=0.05\\p(X_{3}^{t})=p(X_{2}^{{t-1}})p(X_{3}^{t}|X_{2}^{{t-1}})=p(X_{2}^{{t-1}})(0.1)=(0.5)(0.1)=0.05\\p(X_{4}^{t})=p(X_{2}^{{t-1}})p(X_{4}^{t}|X_{2}^{{t-1}})=p(X_{2}^{{t-1}})(0.8)=(0.5)(0.8)=0.40\\\\p(X_{5}^{t})=p(X_{2}^{{t-1}})p(X_{5}^{t}|X_{2}^{{t-1}})+p(X_{4}^{{t-1}})p(X_{5}^{t}|X_{4}^{{t-1}})\\=p(X_{2}^{{t-1}})(0.1)+p(X_{4}^{{t-1}})(0.1)=(0.5)(0.1)+(0.5)(0.1)=0.1\end{array} \tag{5}$$</p>  

<br>

Voila. We derived final probabilities. Visualizing,  

<br>

<div style="display: flex; justify-content: center;">
<figure>
<img src="../../images/2018-03-22_11h01_52.png"/>
<figcaption align='center'>Figure 5</figcaption>
</figure>
</div>  

<br>

Note that, all $ \displaystyle {p(X_{i}^{t})}$ add up to 1. That is,  

<br>

<p>
$$ \displaystyle \sum\limits_{{k=1}}^{n}{{p(X_{i}^{t})=1}}$$</p>

<br>

Thus, $ \displaystyle {p(X_{i}^{t})}$ is <span style="color:#0000ff;">already a posterior probability or same as joint probability as no distinguishing between them needed</span>.  This is an important inference. Further,<span style="color:#0000ff;"> "movement" only caused the distribution to "shift" in direction of robot</span> to other cells, unlike our earlier case "<a href="https://parthibanrajendran.wordpress.com/2018/03/21/5-robot-localization-sense/" target="_blank" rel="noopener">sense</a>".  

<br>

<strong>Food for thought:</strong> Try a simpler case as below for move example, with 100% certainty for initial location and exact movement of robot with no under or overshoot and these would be much more evident.  

<br>

<div style="display: flex; justify-content: center;">
<figure>
<img src="../../images/2018-03-22_13h44_31.png"/>
<figcaption align='center'>Figure 6</figcaption>
</figure>
</div>  

<br>

<strong>Generalization</strong>:

Coming back to our initial example,  lets examine say X<sub>1</sub> . We know, robot could have come to it only from X<sub>4</sub> in our case, so possibility from all other cells would be 0.  

<br>

<p>
$ \displaystyle p(X_{1}^{t})=0+p(X_{4}^{{t-1}})p(X_{1}^{t}|X_{4}^{{t-1}})$  </p>

<br>

If we try to generalize case of X<sub>1</sub> to include all locations, it would be like below and only that except $ \displaystyle p(X_{4}^{{t-1}})p(X_{1}^{t}|X_{4}^{{t-1}})$, other factors ended up 0 as below. For eg, $ \displaystyle p(X_{1}^{t}|X_{2}^{{t-1}})$ is 0 because, no way robot would have come from X<sub>2</sub> to X<sub>1</sub>.  

<br>

<p>
$$ \displaystyle \begin{array}{l}p(X_{1}^{t})=p(X_{1}^{{t-1}})p(X_{1}^{t}|X_{1}^{{t-1}})+p(X_{2}^{{t-1}})p(X_{1}^{t}|X_{2}^{{t-1}})\\+p(X_{3}^{{t-1}})p(X_{1}^{t}|X_{3}^{{t-1}})+p(X_{4}^{{t-1}})p(X_{1}^{t}|X_{4}^{{t-1}})+p(X_{5}^{{t-1}})p(X_{1}^{t}|X_{5}^{{t-1}})\\\\=p(X_{1}^{{t-1}})(0)+p(X_{2}^{{t-1}})(0)+p(X_{3}^{{t-1}})(0)+p(X_{4}^{{t-1}})(0.1)+p(X_{5}^{{t-1}})(0)\\=p(X_{1}^{{t-1}})(0)+p(X_{2}^{{t-1}})(0)+p(X_{3}^{{t-1}})(0)+(0.5)(0.8)+p(X_{5}^{{t-1}})(0)=0.40\end{array} \tag{6} $$
</p>  

<br>

Generalizing this further for any cell X<sub>i</sub>, we get,  

<br>

<p>
$$ \displaystyle \begin{array}{l}p(X_{i}^{t})=p(X_{1}^{{t-1}})p(X_{i}^{t}|X_{1}^{{t-1}})+p(X_{2}^{{t-1}})p(X_{i}^{t}|X_{2}^{{t-1}})\\+p(X_{3}^{{t-1}})p(X_{i}^{t}|X_{3}^{{t-1}})+p(X_{4}^{{t-1}})p(X_{i}^{t}|X_{4}^{{t-1}})+p(X_{5}^{{t-1}})p(X_{i}^{t}|X_{5}^{{t-1}})\end{array} \tag{7} $$
</p>


Formulating, we get:

<p>
$$ \displaystyle p(X_{i}^{t})=\sum\limits_{{k=1}}^{n}{{p(X_{k}^{{t-1}})p(X_{i}^{t}|X_{k}^{{t-1}})}} \tag{8} $$</p>  

<br>

This equation above is called "<span style="color:#0000ff;">Theorem of Total Probability</span>". The above equation is responsible for shifting of the distribution and this  mechanism is generally called "<span style="color:#0000ff;">convolution</span>". Sounds cool, eh?!  

<br>

<strong>Python Implementation:</strong>  

<br>

Assume,  

<br>

<span style="color:#0000ff;"><em>p</em></span> = list of prior probabilities of all cells<br>
<span style="color:#0000ff;"><i>U</i></span> = robot's movement in steps (in our case, its 2)<br>
<span style="color:#0000ff;"><em>pExact</em> </span>= probability of robot exactly finishes 2 steps and ends up at <strong>U</strong>th (2nd in our case) cell to its right<br>
<span style="color:#0000ff;"><i>pUndershoot </i></span>= probability of robot undershoots, and ends up at <strong>(U-1)th</strong> cell (1st cell in our case) to its right<br>
<span style="color:#0000ff;"><em>pOvershoot</em></span> = probability of robot overshoots and ends up at <strong>(U+1)th</strong> cell (3rd cell in our case) to its right  <br>  

<br>

The approach is little bit tricky. So let's hard code for our logic and see if we could derive general code out of it. Let us take another list '<strong>q</strong>' same size as p and try to calculate c<strong>ase A</strong>. We could visualize as below.  

<br>

<div style="display: flex; justify-content: center;">
<figure>
<img src="../../images/2018-03-22_11h43_02.png"/>
<figcaption align='center'>Figure 7: Case A</figcaption>
</figure>
</div>

<br>

Then we could readily calculate, non zero values of <strong>q</strong> from diagram as below.  

<br>

<p style="text-align:left;">q[2] = p[1](0.1) = (0.5)(0.1) = 0.05
q[3] = p[1](0.8) = (0.5)(0.8) = 0.40
q[4] = p[1](0.1) = (0.5)(0.1) = 0.05<span style="float:right;">(9)</span></p>

<br>

Now the <strong>'new' q</strong> would be as below.  

<br>

<div style="display: flex; justify-content: center;">
<figure>
<img src="../../images/2018-03-22_12h02_19.png"/>
<figcaption align='center'>Figure 8: Case B on top of Case A</figcaption>
</figure>
</div>  

<br>

Now <strong>case B</strong>, but on <strong>'new' q</strong>, because we should not lose old q values as probabilities add up. Recall (2).  

<br>

<p style="text-align:left;">q[0] = p[3](0.8) + q[0] = (0.5)(0.8) + 0 = 0.40
q[1] = p[3](0.1) + q[1] = (0.5)(0.1) + 0 = 0.05
q[4] = p[3](0.1) + q[4] = (0.5)(0.1) + 0.05 = 0.10<span style="float:right;">(10)</span></p>

<br>

Note how case A and B added up for q[4]. The resultant distribution might look like this:  

<br>

<div style="display: flex; justify-content: center;">
<figure>
<img src="../../images/2018-03-22_12h25_20.png"/>
<figcaption align='center'>Figure 9: Final distribution in list 'q'</figcaption>
</figure>
</div>  

<br>

Generalizing from both above equations, and re writing again we get:  

<br>

q[2] = p<a href="0.1">1</a> + q[2] = (0.5)(0.1) + 0 = 0.05 <span style="float:right;">#undershoot</span><br>
q[3] = p<a href="0.8">1</a> + q[3] = (0.5)(0.8) + 0 = 0.40 <span style="float:right;">#exact</span><br>
q[4] = p<a href="0.1">1</a> + q[4] = (0.5)(0.1) + 0 = 0.05 <span style="float:right;">#overshoot</span><br> 
q[4] = p<a href="0.1">3</a> + q[4] = (0.5)(0.1) + 0.05 = 0.10 <span style="float:right;">#undershoot</span><br>
q[0] = p<a href="0.8">3</a> + q[0] = (0.5)(0.8) + 0 = 0.40 <span style="float:right;">#exact</span><br>
q[1] = p<a href="0.1">3</a> + q[1] = (0.5)(0.1) + 0 = 0.05 <span style="float:right;">#overshoot</span><br>  

<br>

Note that, we calculated only for 2 cases involving <strong>p[1]</strong> and <strong>p[3]</strong>, as it was evident from our case. We could extend this for all p elements. Visualize to imagine target q elements for each element of p to calculate its probabilities.  

<br>

q[1] = p<a href="0.1">0</a> + q[1]<br>
q[2] = p<a href="0.8">0</a> + q[2]<br>
q[3] = p<a href="0.1">0</a> + q[3]<br>
q[2] = p<a href="0.1">1</a> + q[2]<br>
q[3] = p<a href="0.8">1</a> + q[3]<br>
q[4] = p<a href="0.1">1</a> + q[4]<br>
q[3] = p<a href="0.1">2</a> + q[3]<br>
q[4] = p<a href="0.8">2</a> + q[4]<br>
q[0] = p<a href="0.1">2</a> + q[0]<br>
q[4] = p<a href="0.1">3</a> + q[4]<br>
q[0] = p<a href="0.8">3</a> + q[0]<br>
q[1] = p<a href="0.1">3</a> + q[1]<br>  

<br>

q[0] = p<a href="0.1">4</a> + q[0]<br>
q[1] = p<a href="0.8">4</a> + q[1]<br>
q[2] = p<a href="0.1">4</a> + q[2]<br>   

<br>

Some might have already observed an emerging pattern. Let us quickly check the code, if this works fine before we generalize.  

<br>

In below code, we just create an empty q list of same size as p, (and a temp list for undershoot/exact/overshoot probabilities). Then we update for each element p with above logic and then simply return the updated q.  

<br>

```python
p=[0, 0.5, 0, 0.5, 0]
pExact = 0.8
pOvershoot = 0.1
pUndershoot = 0.1
def move(p, U):
    """
    p = given probability distribution list
    U = amount of steps robot has moved to right (assumed as right for now)
    """
    # INEXACT MOTION
    q = [ 0 for _ in p ]
    temp = [pUndershoot, pExact, pOvershoot]
    q[1] = p[0]<em>temp[0] + q[1]
    q[2] = p[0]</em>temp[1] + q[2]
    q[3] = p[0]*temp[2] + q[3]

<pre><code>q[2] = p[1]*temp[0] + q[2]
q[3] = p[1]*temp[1] + q[3]
q[4] = p[1]*temp[2] + q[4]

q[3] = p[2]*temp[0] + q[3]
q[4] = p[2]*temp[1] + q[4]
q[0] = p[2]*temp[2] + q[0]

q[4] = p[3]*temp[0] + q[4]
q[0] = p[3]*temp[1] + q[0]
q[1] = p[3]*temp[2] + q[1]

q[0] = p[4]*temp[0] + q[0]
q[1] = p[4]*temp[1] + q[1]
q[2] = p[4]*temp[2] + q[2]
return q


print("Prior probability: " + str(p))
print("Posterior probability: " + str(move(p,2)))
```  

<br>

Output:<br>
<img class="alignnone size-full wp-image-190" src="../../images/2018-03-22_12h47_36.png" alt="2018-03-22_12h47_36" width="386" height="57" />  

<br>

Great, this works. Now let us condense it to generalize. We need to run for all elements of p, so that calls for a for loop. Tricky part is the indexing of q. Check the flow of q indexes. Its { (1,2,3) , (2,3,4), (3,4,0) ...}  

<br>

If we run a for loop, the p's index could be used to calculate q's index by using undershoot, exact and overshoot target cell location relative to current p's index.  

<br>

For example, in case of <strong>p[1]</strong>, we could also re write as below (remember, <strong>U = 2</strong> in our case).  

<br>

q[ <span style="color:#0000ff;">(1 + (U-1))</span> ] = p[1]<em>temp[0] + q[ <span style="color:#0000ff;">(1 + (U-1))</span> ]<br>
q[ <span style="color:#0000ff;">(1 + U)</span> ] = p[1]</em>temp[1] + q[ <span style="color:#0000ff;">(1 + U)</span> ]<br>
q[ <span style="color:#0000ff;">(1 + (U+1))</span> ] = p[1]*temp[2] + q[<span style="color:#0000ff;"> (1 + (U+1))</span> ] <br> 

You can verify that, substituting for U, you get the same as what you got earlier. That is,  

<br>
 
q[<span style="color:#0000ff;">2</span>] = p[1]<em>temp[0] + q[<span style="color:#0000ff;">2</span>]<br>
q[<span style="color:#0000ff;">3</span>] = p[1]</em>temp[1] + q[<span style="color:#0000ff;">3</span>]<br>
q[<span style="color:#0000ff;">4</span>] = p[1]*temp[2] + q[<span style="color:#0000ff;">4]</span><br>  

<br>

Good. But what about edge elements. Try doing the same for <strong>p[3]</strong> with <strong>U=2</strong>.  

<br>

q[ <span style="color:#0000ff;">(3 + (U-1))</span> ] = p[3]<em>temp[0] + q[ <span style="color:#0000ff;">(3 + (U-1))</span> ]<br>
q[ <span style="color:#0000ff;">(3 + U)</span> ] = p[3]</em>temp[1] + q[ <span style="color:#0000ff;">(3 + U)</span> ]<br>
q[ <span style="color:#0000ff;">(3 + (U+1))</span> ] = p[3]*temp[2] + q[ <span style="color:#0000ff;">(3 + (U+1))</span> ]<br>  

<br>

becomes  

<br>

q[ <span style="color:#0000ff;">4</span> ] = p[3]<em>temp[0] + q[<span style="color:#0000ff;"> 4</span> ]<br>
q[ <span style="color:#0000ff;">5</span> ] = p[3]</em>temp[1] + q[ <span style="color:#0000ff;">5</span> ]<br>
q[ <span style="color:#0000ff;">6</span> ] = p[3]*temp[2] + q[ <span style="color:#0000ff;">6</span> ]<br>  

<br>

Oh ho. You can see, this calculation simply overflows beyond max index of q. We said, our 1D is cyclic. Thus we should be getting,  

<br>

q[<span style="color:#0000ff;">4</span>] = p[3]<em>temp[0] + q[<span style="color:#0000ff;">4</span>]<br>
q[<span style="color:#0000ff;">0</span>] = p[3]</em>temp[1] + q[<span style="color:#0000ff;">0</span>]<br>
q[<span style="color:#0000ff;">1</span>] = p[3]*temp[2] + q[<span style="color:#0000ff;">1</span>]<br>  

<br>

<strong>So after q[4], we should get q[0].</strong> Modulo operator comes to the rescue here.

<br>

Note that, <strong>5 % 5 = 0, 6 % 5 = 1</strong>, the exact numbers we need. Mod does not affect when numerator is smaller. for eg, <strong>4 % 5 is still 4.</strong> Perfect! Substituting that, and taking off the index calculations for q for brevity, we get the logic as below.  

<br>

undershoot_index = <span style="color:#0000ff;">(i + (U-1)) % len(p)</span><br>
exact_index = <span style="color:#0000ff;">(i + (U)) % len(p)</span><br>
overshoot_index = <span style="color:#0000ff;">(i + (U+1)) % len(p)</span><br>

<br>

q[ <span style="color:#0000ff;">undershoot_index</span> ] = p[i]<em>temp[0] + q[ <span style="color:#0000ff;">undershoot_index</span> ]<br>
q[ <span style="color:#0000ff;">exact_index</span> ] = p[i]</em>temp[1] + q[ <span style="color:#0000ff;">exact_index</span> ]<br>
q[ <span style="color:#0000ff;">overshoot_index</span> ] = p[i]*temp[2] + q[ <span style="color:#0000ff;">overshoot_index</span> ]<br>  

<br>

Let us now try this generalized approach. This time, we use a for loop, and inside that, above logic.  

<br>

```python
 p=[0, 0.5, 0, 0.5, 0]
 pExact = 0.8
 pOvershoot = 0.1
 pUndershoot = 0.1
 def move(p, U):
 """
 p = given probability distribution list
 U = amount of steps robot has moved to right (assumed as right for now)
 """
 ### INEXACT MOTION
 q = [ 0 for _ in p ]
 temp = [pUndershoot, pExact, pOvershoot]

for i in range(len(p)):
 undershoot_index = (i + (U-1)) % len(p)
 exact_index = (i + (U)) % len(p)
 overshoot_index = (i + (U+1)) % len(p)
 q[ undershoot_index ] = p[i]<em>temp[0] + q[ undershoot_index ]
 q[ exact_index ] = p[i]</em>temp[1] + q[ exact_index ]
 q[ overshoot_index ] = p[i]*temp[2] + q[ overshoot_index ]

return q

print("Prior probability: " + str(p))
 print("Posterior probability: " + str(move(p,2)))
```  

<br>

<strong>Output:</strong><br>
<img class="alignnone size-full wp-image-191" src="../../images/2018-03-22_13h01_45.png" alt="2018-03-22_13h01_45" width="413" height="57" />  

<br>

It works :)  

<br>

You could try with different values of p, U and see that the program works.  

<br>

<strong>Interesting observation:</strong> What if the robot keeps on moving 2 steps at a time. Intuitively over time, the uncertainty approaches maximum: robot is equally likely to be present in any cell. In other words, each cell would have (1/5) = 0.2 probability in our case of 1 D space of 5 cells.  

<br>

<div style="display: flex; justify-content: center;">
<figure>
<img src="../../images/2018-03-22_13h30_04.png"/>
<figcaption align='center'>Figure 10</figcaption>
</figure>
</div>

<br>

Let us check the code, calling the move for, say 1000 times.  

<br>

```python
p=[0, 0.5, 0, 0.5, 0]
print("Prior probability: " + str(p))
for i in range(1000):
    p = move(p,2)
print("Posterior probability: " + str(move(p,2)))
```  

<br>

Output:  

<br>
<img class="alignnone size-full wp-image-193" src="../../images/2018-03-22_13h27_42.png" alt="2018-03-22_13h27_42" width="874" height="58" />  

<br>

We got 0.2 for all cells :)  

<br>

So when you just move every time, without 'sensing' any new information, uncertainty increases.  

<br>

## Part 3 (Combination)

<p>We have implemented two important functions for robot localization. Sense gains new information and increases certainty of robot&apos;s localization. Move loses information increasing uncertainty of robot&apos;s localization. So both should be alternatively and accordingly used for successful navigation of robots.</p>  

<br>  

<p>Note when we say sense or move, we only update probability distribution given robot&apos;s capability for sense and motion. We did not operate robot directly yet.That said, let us again re imagine our 1 D world again. Note also, we assume U = 1, that is, robot moving 1 cell at a time.</p>  

<br>

<img class="alignnone size-full wp-image-213" src="../../images/2018-03-22_15h17_04.png" alt="2018-03-22_15h17_04" width="390" height="136"><br>  
<img class="alignnone size-full wp-image-214" src="../../images/2018-03-22_15h17_31.png" alt="2018-03-22_15h17_31" width="412" height="374"><br>  

<br>

<p>Suppose,</p>
<ol>
<li>Robot senses &apos;red&apos;</li>
<li>Move one step to right</li>
<li>Robot senses &apos;green&apos;</li>
</ol>
<p>What would be its current location intuitively? By looking at the map, we could say, its X<sub>4</sub>. But how could robot with all its sense and move inaccuracies fare in detecting that location? Let us calculate the resultant probability distribution.</p>

```python  
#Just for visualization
import matplotlib.pyplot as plt
def output_map(grid):
"""
outputs a bar chart showing the probabilities of each grid space
"""
x_labels = []
for index in range(len(grid)):
x_labels.append(index)
plt.bar(x_labels, grid)

<h1>Create names on the axes</h1>

plt.title('Probability of the robot being at each space on the grid')
plt.xlabel('1D Space')
plt.ylabel('Probability')
plt.show(block=True)

#initial probability
p=[0.2, 0.2, 0.2, 0.2, 0.2]

#sense
world=['green', 'red', 'red', 'green', 'green']
pHit = 0.6
pMiss = 0.2

#move
pExact = 0.8
pOvershoot = 0.1
pUndershoot = 0.1

#our operation
print("Prior probability: " + str(p))
p = sense(p, 'red')
p = move(p , 1)
p = sense(p , 'green')
print("Posterior probability: " + str(p))
output_map(p)
```

<p>Output:<br>
<img class="alignnone size-full wp-image-218" src="../../images/2018-03-22_15h25_45.png" alt="2018-03-22_15h25_45" width="891" height="58"></p>  

<br>


<p>I have also included a visualization, so the result is obvious.<br>
<img class="alignnone size-full wp-image-219" src="../../images/2018-03-22_15h25_36.png" alt="2018-03-22_15h25_36" width="640" height="480"></p>

</div>